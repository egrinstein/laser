# This script parses the AudioCaps mix.csv file (generated by parsing the AudioCaps .csv using the script data/mixing/audiocaps_csv_mixer.py)
# and creates gramatically correct commands for the mixed audio clips, as well as their corresponding CLAP embeddings.
# an AudioCaps mix.csv file contains the following columns:
# ,audiocap_id_target,audiocap_id_interferer, youtube_id_target, youtube_id_interferer, start_time_target, start_time_interferer, caption_target, caption_interferer, caption_similarity
# The script will create a directory containing two files per mixed audio clip. One contains the embeddings in the .safetensors format.
# The other contains the command in the .json format, with the keys "command" and "type".

import argparse
import json
import os
import pandas as pd

from tqdm import tqdm

from joblib import Parallel, delayed
from commander import CommandCreator
from models.clap_encoder import ClapEncoder
from models.bert_encoder import BertEncoder
from safetensors.torch import save_file


def create_commands(in_csv_path, out_dir_path, mode = "e2e",
                    encoder='bert', use_corrector = True, n_jobs = 1,
                    re_encode = True):
    """

    Args:
        in_csv_path (str): path to input mix.csv file
        out_dir_path (str): path to output directory where the commands will be saved
        mode (str, optional): "template" will construct the commands from available templates,
        followed by gramatical correction using deep learning. Conversely, "e2e" will ask a GPT to generate a command. Defaults to "template".    """


    os.makedirs(out_dir_path, exist_ok=True)

    df = pd.read_csv(in_csv_path)
    
    command_creator = CommandCreator(mode=mode, use_corrector=use_corrector)
    
    if encoder == 'bert':
        encoder = BertEncoder().eval()
    elif encoder == 'clap':
        encoder = ClapEncoder().eval()

    def _process_row(row):
        target_caption = row['caption_target']
        interferer_caption = row['caption_interferer']
        out_file_path = os.path.join(
            out_dir_path, f"{row['audiocap_id_target']}_{row['audiocap_id_interferer']}")
        out_json_path = os.path.join(f"{out_file_path}.json")
        out_embed_path = os.path.join(f"{out_file_path}.safetensors")

        if os.path.exists(out_json_path):
            json_data = json.load(open(out_json_path))
            command_text = json_data['command']
            command_type = json_data['type']

            if os.path.exists(out_embed_path):
                if not re_encode:
                    # Skip if the files already exist
                    return
                else:
                    print(f"Re-encoding {out_embed_path}")
        else:
            command_text, command_type = command_creator(
                target_caption, [interferer_caption])
            
        if command_text is None:
            print(f"Skipping row {row} as command could not be generated")
            return

        command_embedding = encoder([command_text])[0]
        # print(f"[{out_file_path}]", command_text)

        # Save the command embedding and its text
        save_file( {
            'command': command_embedding,
        }, out_embed_path)

        with open(out_json_path, 'w') as f:
            json.dump({
                'command': command_text,
                'type': command_type,
                'target_caption': target_caption,
                'interferer_caption': interferer_caption
            }, f)

    Parallel(n_jobs=n_jobs, require='sharedmem')(
        delayed(_process_row)(row) for i, row in tqdm(df.iterrows(), total=len(df)))


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Create AudioCaps commands')
    parser.add_argument('--in_csv_dir', type=str, help='Path to input mix.csv files (train, val, test)')
    parser.add_argument('--out_dir', type=str, help='Path to output directory where the commands will be saved')
    parser.add_argument('--mode', type=str, default='template', help='Mode to create commands. Either "template" or "e2e"')
    parser.add_argument('--dont_use_corrector', action='store_true', help='Use the corrector to generate commands')
    parser.add_argument('--n_jobs', type=int, default=1, help='Number of parallel jobs to run')
    args = parser.parse_args()

    for split in ['train', 'test', 'val']:
        in_csv_path = os.path.join(args.in_csv_dir, f"audiocaps_{split}_mix.csv")
        out_dir_path = os.path.join(args.out_dir, split)
        create_commands(in_csv_path, out_dir_path, mode=args.mode,
                        use_corrector=not args.dont_use_corrector, n_jobs=args.n_jobs)
