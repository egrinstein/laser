---
task_name: AudioSep

data:
    train_datafiles:
        - 'config/datafiles/audiocaps_train_mix.json'
    val_datafiles:
        - 'config/datafiles/audiocaps_val_mix.json'
    test_datafiles:
        - 'config/datafiles/audiocaps_test_mix.json'

    sampling_rate: 32000
    segment_seconds: 5
    loudness_norm:
        lower_db: -10
        higher_db: 10
    max_mix_num: 2
    is_premixed: true

model:
    backbone: lassnet
    query_encoder: bert # 'bert' or 'clap'
    condition_size: 256

    input_channels: 1
    output_channels: 1
    only_train_film: true

train:
    optimizer:
        optimizer_type: AdamW
        learning_rate: 1e-3
        warm_up_steps: 10000
        reduce_lr_steps: 1000000
        lr_lambda_type: constant_warm_up
    num_nodes: 1
    num_workers: 1
    loss_type: l1_wav
    sync_batchnorm: True
    batch_size_per_device: 6
    save_step_frequency: 3000  # Save every #save_step_frequency steps.
    checkpoint_path: checkpoint/LASSNet.pt
    n_epochs: 7

accelerator: mps
device: null
